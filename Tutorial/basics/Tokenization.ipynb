{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d116d52f-f1bb-4c2b-942e-63188e65d77d",
   "metadata": {},
   "source": [
    "#### Tokenization is the process of splitting text into meaningful segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4150d6f-4306-495d-a2a1-54f5de968249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef326a8-59d9-4ecb-a632-65ae1d753a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7dde1a3-d860-4b81-aac2-2f1ec80f0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Dr. Samrat loves momo of Pokhara as it costs only 2$ per plate.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "353a6312-d033-4307-b4f6-0c907baf2dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Samrat\n",
      "loves\n",
      "momo\n",
      "of\n",
      "Pokhara\n",
      "as\n",
      "it\n",
      "costs\n",
      "only\n",
      "2\n",
      "$\n",
      "per\n",
      "plate\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d011751-9725-443f-ac82-e44ababbe567",
   "metadata": {},
   "source": [
    "<img src='assets\\tokenization.png' width=500 height=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5d15fab-e725-482e-a69c-f9215296e7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "new_doc = nlp('''\"Let's go to N.Y.!\"''')\n",
    "for token in new_doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ff9614c-47ed-4977-bfe0-d741cafe6552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Samrat loves momo of Pokhara"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = doc[1:6]\n",
    "doc[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9118d600-c96d-44e1-92a8-c0495ce86f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(spacy.lang.en.English,\n",
       " spacy.tokens.doc.Doc,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.span.Span)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp), type(doc), type(token), type(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc00398d-aa13-47b9-ba03-f0699aeac55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tony"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('Tony gave two $ to Peter.')\n",
    "token = doc[0]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61a2698a-7a23-4ca8-997d-fbcfaff5bd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b792695e-e8ae-4231-828f-2cab2ffda5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e534f82-2a26-4bd6-8dfd-58d53e63a25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[2]\n",
    "token.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c8b6ca9-848e-4521-a74f-b747d18ff574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81f5b8bb-d9f0-4232-a02f-081625baf73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[3]\n",
    "token.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d01e5bd6-1c5e-466a-83c3-7ca2e5dffc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8ac49eb-53de-41af-83d3-f81c568bf906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony \t\t index: 0 is_alpha: True like_punct: False like_num: False is_currency: False\n",
      "gave \t\t index: 1 is_alpha: True like_punct: False like_num: False is_currency: False\n",
      "two \t\t index: 2 is_alpha: True like_punct: False like_num: True is_currency: False\n",
      "$ \t\t index: 3 is_alpha: False like_punct: False like_num: False is_currency: True\n",
      "to \t\t index: 4 is_alpha: True like_punct: False like_num: False is_currency: False\n",
      "Peter \t\t index: 5 is_alpha: True like_punct: False like_num: False is_currency: False\n",
      ". \t\t index: 6 is_alpha: False like_punct: True like_num: False is_currency: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, '\\t\\t index:', token.i, 'is_alpha:', token.is_alpha, \n",
    "          'like_punct:', token.is_punct, 'like_num:', token.like_num, \n",
    "          'is_currency:', token.is_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5815dccd-ac4d-4551-901f-9904fbca8967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harvard University\\n',\n",
       " '===================================================================\\n',\n",
       " '\\n',\n",
       " 'Name        Birth day        email\\n',\n",
       " '----        ---------        -----\\n',\n",
       " 'Samrat      5 June, 1990     samrat@metal.com\\n',\n",
       " 'Killer      6 Jan, 1880      killer@bee.com\\n',\n",
       " 'Yeti        17 May, 2000     mr@yeti.com\\n',\n",
       " 'Ubermensch  10 Feb, 1992     ubermensch@superman.com']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('assets/tokenization.txt') as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7411ef07-bf1e-4123-b8fa-78d869e2e1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harvard University\\n ===================================================================\\n \\n Name        Birth day        email\\n ----        ---------        -----\\n Samrat      5 June, 1990     samrat@metal.com\\n Killer      6 Jan, 1880      killer@bee.com\\n Yeti        17 May, 2000     mr@yeti.com\\n Ubermensch  10 Feb, 1992     ubermensch@superman.com'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9796f794-df6f-4156-892e-8ef5b55e76fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['samrat@metal.com',\n",
       " 'killer@bee.com',\n",
       " 'mr@yeti.com',\n",
       " 'ubermensch@superman.com']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "emails = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        emails.append(token.text)\n",
    "\n",
    "emails        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c62121d-5a3f-44c2-a9b5-983da091544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('ne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b144182-ac16-47c8-9449-ee592e894b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'नमस्ते सबैला। आशा छ सबै जना सन्चै हुनुहुन्छ होला। म पनि यता आरामै छु! हजुरको नाम क हो? मसंग रू. ५ छ। '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd728111-fb13-41e7-ad9f-396ffa546b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्ते \t\t index: 0 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "सबैला \t\t index: 1 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "। \t\t index: 2 is_alpha: False like_punct: True like_num: False is_currency: False\n",
      "आशा \t\t index: 3 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "छ \t\t index: 4 is_alpha: True like_punct: False like_num: True is_currency: False\n",
      "सबै \t\t index: 5 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "जना \t\t index: 6 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "सन्चै \t\t index: 7 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "हुनुहुन्छ \t\t index: 8 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "होला \t\t index: 9 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "। \t\t index: 10 is_alpha: False like_punct: True like_num: False is_currency: False\n",
      "म \t\t index: 11 is_alpha: True like_punct: False like_num: False is_currency: False\n",
      "पनि \t\t index: 12 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "यता \t\t index: 13 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "आरामै \t\t index: 14 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "छु \t\t index: 15 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "! \t\t index: 16 is_alpha: False like_punct: True like_num: False is_currency: False\n",
      "हजुरको \t\t index: 17 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "नाम \t\t index: 18 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "क \t\t index: 19 is_alpha: True like_punct: False like_num: False is_currency: False\n",
      "हो \t\t index: 20 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "? \t\t index: 21 is_alpha: False like_punct: True like_num: False is_currency: False\n",
      "मसंग \t\t index: 22 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      "रू \t\t index: 23 is_alpha: False like_punct: False like_num: False is_currency: False\n",
      ". \t\t index: 24 is_alpha: False like_punct: True like_num: False is_currency: False\n",
      "५ \t\t index: 25 is_alpha: False like_punct: False like_num: True is_currency: False\n",
      "छ \t\t index: 26 is_alpha: True like_punct: False like_num: True is_currency: False\n",
      "। \t\t index: 27 is_alpha: False like_punct: True like_num: False is_currency: False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token, '\\t\\t index:', token.i, 'is_alpha:', token.is_alpha, \n",
    "          'like_punct:', token.is_punct, 'like_num:', token.like_num, \n",
    "          'is_currency:', token.is_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb6ca188-de18-40b5-8051-86a9c82ec726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('gimme double cheese extra large healthy pizza')\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db31d59a-5114-458f-9834-122ac9ff88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e24671b3-89d2-49c9-97c4-c68748419db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer.add_special_case('gimme', [\n",
    "    {ORTH: 'gim'},\n",
    "    {ORTH: 'me'}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27595e80-690e-48b8-b86e-bc98f7a69158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('gimme double cheese extra large healthy pizza')\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "216b69a1-3538-41c9-b62c-fb89db2e48c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97161f5f-da3b-4f11-bea2-23f9a87e4a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x2553ba13dd0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "93ec7017-b950-4863-b616-267baf93ee09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentencizer']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ccfd0fc-6c9d-4c87-a871-323a7044c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange loves momo of pokhara.\n",
      "Hulk loves yomari of kathmandu.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Dr. Strange loves momo of pokhara. Hulk loves yomari of kathmandu.')\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4493c60-9b2b-41a7-a0a8-e88d59ada81c",
   "metadata": {},
   "source": [
    "### **Exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a6d63-867a-4460-a734-7efd15d1e540",
   "metadata": {},
   "source": [
    "**1. Extract all the urls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f8ed4a2-cef0-4631-9c18-06b00a7ca1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b94d3dd-e341-4086-bcfc-551438aeb488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.data.gov/',\n",
       " 'http://www.science',\n",
       " 'http://data.gov.uk/.',\n",
       " 'http://www3.norc.org/gss+website/',\n",
       " 'http://www.europeansocialsurvey.org/.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "tokens = [token.text for token in doc if token.like_url]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6faf105-dbe4-456b-9f64-cc6205dfa1ec",
   "metadata": {},
   "source": [
    "**2. Extract all the money transaction from below sentence along with currency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3821120c-a9e4-408a-b24b-022c89ed3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70c7aada-abf5-4fb2-a3e5-b74e67584919",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Tony gave two $ to Peter, Bruce gave 500 € to Steve.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6bc3f3ad-4ec4-422b-a059-2de648d76aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    if token.like_num and doc[token.i+1].is_currency:\n",
    "        print(token.text, doc[token.i+1].text)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
